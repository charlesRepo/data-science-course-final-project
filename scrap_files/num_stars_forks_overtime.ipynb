{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from functions import fetch_github_data\n",
    "\n",
    "\n",
    "from config import GITHUB_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch stargazers: 422\n",
      "                       date  num_stars\n",
      "0 2023-03-16 19:57:53+00:00          1\n",
      "1 2023-03-16 21:32:21+00:00          1\n",
      "2 2023-03-17 07:46:00+00:00          1\n",
      "3 2023-03-17 14:52:47+00:00          1\n",
      "4 2023-03-17 15:16:39+00:00          1\n"
     ]
    }
   ],
   "source": [
    "def fetch_stargazers_with_dates(org_name, repo_name, headers):\n",
    "    \"\"\"\n",
    "    Fetches stargazer data for a repository, including the date each star was given.\n",
    "    \"\"\"\n",
    "    url = f'https://api.github.com/repos/{org_name}/{repo_name}/stargazers'\n",
    "    params = {'per_page': 100, 'page': 1}\n",
    "    stars_data = []\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            stars = response.json()\n",
    "            if not stars:\n",
    "                break\n",
    "\n",
    "            # Extract the date each star was added\n",
    "            for star in stars:\n",
    "                stars_data.append(star['starred_at'])\n",
    "            params['page'] += 1\n",
    "        else:\n",
    "            print(f\"Failed to fetch stargazers: {response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    stars_df = pd.DataFrame({'date': pd.to_datetime(stars_data)})\n",
    "    stars_df['num_stars'] = 1  # Each row represents a single star\n",
    "    return stars_df\n",
    "\n",
    "# Example usage\n",
    "headers = {'Authorization': f'token {GITHUB_TOKEN}', 'Accept': 'application/vnd.github.v3.star+json'}\n",
    "org_name = 'Significant-Gravitas'\n",
    "repo_name = 'AutoGPT'\n",
    "stars_df = fetch_stargazers_with_dates(org_name, repo_name, headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           date  num_stars\n",
      "0     2023-03-16 19:57:53+00:00          1\n",
      "1     2023-03-16 21:32:21+00:00          1\n",
      "2     2023-03-17 07:46:00+00:00          1\n",
      "3     2023-03-17 14:52:47+00:00          1\n",
      "4     2023-03-17 15:16:39+00:00          1\n",
      "...                         ...        ...\n",
      "39995 2023-04-13 10:21:22+00:00          1\n",
      "39996 2023-04-13 10:21:27+00:00          1\n",
      "39997 2023-04-13 10:21:30+00:00          1\n",
      "39998 2023-04-13 10:21:32+00:00          1\n",
      "39999 2023-04-13 10:21:46+00:00          1\n",
      "\n",
      "[40000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stars_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch fork events: 422\n",
      "                       date  num_forks\n",
      "0 2024-09-21 13:11:21+00:00          1\n",
      "1 2024-09-21 09:41:10+00:00          1\n",
      "2 2024-09-21 04:44:09+00:00          1\n",
      "3 2024-09-21 01:22:59+00:00          1\n",
      "4 2024-09-20 21:59:24+00:00          1\n"
     ]
    }
   ],
   "source": [
    "def fetch_fork_events_with_dates(org_name, repo_name, headers):\n",
    "    \"\"\"\n",
    "    Fetches fork events for a repository, including the date each fork was created.\n",
    "    \"\"\"\n",
    "    url = f'https://api.github.com/repos/{org_name}/{repo_name}/events'\n",
    "    params = {'per_page': 100, 'page': 1}\n",
    "    fork_data = []\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            events = response.json()\n",
    "            if not events:\n",
    "                break\n",
    "\n",
    "            # Extract the date each fork was created\n",
    "            for event in events:\n",
    "                if event['type'] == 'ForkEvent':\n",
    "                    fork_data.append(event['created_at'])\n",
    "\n",
    "            params['page'] += 1\n",
    "        else:\n",
    "            print(f\"Failed to fetch fork events: {response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    forks_df = pd.DataFrame({'date': pd.to_datetime(fork_data)})\n",
    "    forks_df['num_forks'] = 1  # Each row represents a single fork\n",
    "    return forks_df\n",
    "\n",
    "# Example usage\n",
    "forks_df = fetch_fork_events_with_dates(org_name, repo_name, headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       date  num_forks\n",
      "0 2024-09-21 13:11:21+00:00          1\n",
      "1 2024-09-21 09:41:10+00:00          1\n",
      "2 2024-09-21 04:44:09+00:00          1\n",
      "3 2024-09-21 01:22:59+00:00          1\n",
      "4 2024-09-20 21:59:24+00:00          1\n",
      "5 2024-09-20 20:44:00+00:00          1\n",
      "6 2024-09-20 15:36:59+00:00          1\n",
      "7 2024-09-20 15:02:19+00:00          1\n",
      "8 2024-09-20 14:45:56+00:00          1\n",
      "9 2024-09-20 12:18:21+00:00          1\n"
     ]
    }
   ],
   "source": [
    "print(forks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        date  num_stars  num_forks  num_stars_cumulative  \\\n",
      "0  2023-03-16 00:00:00+00:00        2.0        0.0                   2.0   \n",
      "1  2023-03-17 00:00:00+00:00        8.0        0.0                  10.0   \n",
      "2  2023-03-18 00:00:00+00:00        2.0        0.0                  12.0   \n",
      "3  2023-03-19 00:00:00+00:00        4.0        0.0                  16.0   \n",
      "4  2023-03-20 00:00:00+00:00        2.0        0.0                  18.0   \n",
      "5  2023-03-21 00:00:00+00:00        2.0        0.0                  20.0   \n",
      "6  2023-03-22 00:00:00+00:00        3.0        0.0                  23.0   \n",
      "7  2023-03-23 00:00:00+00:00        0.0        0.0                  23.0   \n",
      "8  2023-03-24 00:00:00+00:00        0.0        0.0                  23.0   \n",
      "9  2023-03-25 00:00:00+00:00        2.0        0.0                  25.0   \n",
      "10 2023-03-26 00:00:00+00:00        1.0        0.0                  26.0   \n",
      "11 2023-03-27 00:00:00+00:00        3.0        0.0                  29.0   \n",
      "12 2023-03-28 00:00:00+00:00       16.0        0.0                  45.0   \n",
      "13 2023-03-29 00:00:00+00:00       22.0        0.0                  67.0   \n",
      "14 2023-03-30 00:00:00+00:00       26.0        0.0                  93.0   \n",
      "15 2023-03-31 00:00:00+00:00        9.0        0.0                 102.0   \n",
      "16 2023-04-01 00:00:00+00:00       84.0        0.0                 186.0   \n",
      "17 2023-04-02 00:00:00+00:00     1436.0        0.0                1622.0   \n",
      "18 2023-04-03 00:00:00+00:00     3051.0        0.0                4673.0   \n",
      "19 2023-04-04 00:00:00+00:00     2626.0        0.0                7299.0   \n",
      "20 2023-04-05 00:00:00+00:00     2340.0        0.0                9639.0   \n",
      "21 2023-04-06 00:00:00+00:00     2668.0        0.0               12307.0   \n",
      "22 2023-04-07 00:00:00+00:00     2426.0        0.0               14733.0   \n",
      "23 2023-04-08 00:00:00+00:00     1670.0        0.0               16403.0   \n",
      "24 2023-04-09 00:00:00+00:00     1668.0        0.0               18071.0   \n",
      "25 2023-04-10 00:00:00+00:00     2501.0        0.0               20572.0   \n",
      "26 2023-04-11 00:00:00+00:00     3978.0        0.0               24550.0   \n",
      "27 2023-04-12 00:00:00+00:00     7777.0        0.0               32327.0   \n",
      "28 2023-04-13 00:00:00+00:00     7673.0        0.0               40000.0   \n",
      "29 2024-09-20 00:00:00+00:00        0.0        6.0               40000.0   \n",
      "30 2024-09-21 00:00:00+00:00        0.0        4.0               40000.0   \n",
      "\n",
      "    num_forks_cumulative  \n",
      "0                    0.0  \n",
      "1                    0.0  \n",
      "2                    0.0  \n",
      "3                    0.0  \n",
      "4                    0.0  \n",
      "5                    0.0  \n",
      "6                    0.0  \n",
      "7                    0.0  \n",
      "8                    0.0  \n",
      "9                    0.0  \n",
      "10                   0.0  \n",
      "11                   0.0  \n",
      "12                   0.0  \n",
      "13                   0.0  \n",
      "14                   0.0  \n",
      "15                   0.0  \n",
      "16                   0.0  \n",
      "17                   0.0  \n",
      "18                   0.0  \n",
      "19                   0.0  \n",
      "20                   0.0  \n",
      "21                   0.0  \n",
      "22                   0.0  \n",
      "23                   0.0  \n",
      "24                   0.0  \n",
      "25                   0.0  \n",
      "26                   0.0  \n",
      "27                   0.0  \n",
      "28                   0.0  \n",
      "29                   6.0  \n",
      "30                  10.0  \n"
     ]
    }
   ],
   "source": [
    "# Combine star and fork data into a single DataFrame\n",
    "combined_df = pd.concat([stars_df.set_index('date').resample('D').sum(),\n",
    "                        forks_df.set_index('date').resample('D').sum()], axis=1).fillna(0)\n",
    "\n",
    "# Accumulate the values over time\n",
    "combined_df['num_stars_cumulative'] = combined_df['num_stars'].cumsum()\n",
    "combined_df['num_forks_cumulative'] = combined_df['num_forks'].cumsum()\n",
    "\n",
    "# Reset index to have date as a column\n",
    "combined_df.reset_index(inplace=True)\n",
    "print(combined_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
