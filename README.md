# Project description

### Forecasting Growth Scores for GitHub Repositories Using Machine Learning

This project involves building a web-based application that predicts the growth score of a GitHub repository over a specified time period. This growth score is derived from metrics like stars, forks, pull requests, and open issues. The application utilizes a Recurrent Neural Network (RNN) with attention mechanism to make accurate predictions based on time-series data.

# App link
[App Link](https://ds-final-project-repo-growth-forecast.streamlit.app/)

# Files & directories description
- __src__: 
  -  `functions.py` has all the necessary functions that make the app work 
  -  `app.py` is the main app file
  -  `test.py` was mainly used for experimentation
- __notebooks__: 
  - `main.ipynb` where the bulk of exploration work took place, and where the RNN model, scaling and PCA models have been generated
  - `generate_data.ipynb` this is the file which was used to get, merge, and augment the data from the various Github repositories
  - `manual_test.ipynb` is the file that tests the model forecasting capability on a single repositories
- __models__: holds the different RNN model, trainging and testing scaling model and input data PCA models, as well as the grid search tuning log files for the LSTM and the GRU models
- __data__: 
  - `github_data.csv` the main CSV file generated by the `generate_data.ipynb` file
  - `topic_embeddings.csv` is the embeddings of topics generated by the Transformers library, it is saved in a CSV file for quickly re-running the main notebook from the start (no need to wait for embeddings conversion the CSV file can be used). Make sure to delete this file after data regeneration.
- __docs__: holds the initial project proposal, and project links
- __scrap_files__ contains different notebooks that were used for experimentation and proof of concepts
- __requirements.txt__ lists all the various Python packages that was used for this project

# Running the notebooks on your local
- create a `config.py` file in the root directory and insert your Github Access Token in the form of `GITHUB_TOKEN = 'you_access_token'`
- install all the required packages listed in `requirements.txt`


# Enabling the app on your local
1. Fork and pull this repo to your local
2. cd `data-science-course-final-project`
3. make sure to install all the packages in the requirement.txt app
4. Generate a new Github Access Token and save the token localy under `~/.streamlit/secrets.toml` in the form of `GITHUB_TOKEN = 'you_access_token'` (you may need to create the `secrets.toml` file)
5. run `python3 -m streamlit run ./src/app.py` this will open the app in the browser on http://localhost:8501/
